## **PoC: AutomaÃ§Ã£o de Code Review e Qualidade de CÃ³digo com GitHub Copilot**

Este repositÃ³rio serve como uma Prova de Conceito (PoC) para demonstrar a aplicaÃ§Ã£o de InteligÃªncia Artificial, via **GitHub Copilot**, na automaÃ§Ã£o e padronizaÃ§Ã£o do processo de *Code Review* para a Plataforma de Dados (Data Platform).

O foco Ã© validar a arquitetura de *commits* e arquivos de configuraÃ§Ã£o (OrquestraÃ§Ã£o, Metadados e Scripts SQL) antes que o cÃ³digo seja mesclado Ã s *branches* principais.

### ğŸ’¡ Objetivo da PoC

O objetivo principal Ã© codificar o conhecimento de engenharia de dados em **InstruÃ§Ãµes Personalizadas do Copilot** (`.instructions.md`) para garantir:

1.  **Conformidade de ConfiguraÃ§Ã£o:** ValidaÃ§Ã£o do formato JSON em arquivos de orquestraÃ§Ã£o e metadados.
2.  **Integridade do Pipeline:** Garantia de que cada job de orquestraÃ§Ã£o tenha seu arquivo de metadados correspondente.
3.  **Qualidade do CÃ³digo Spark SQL:** RevisÃ£o automatizada da sintaxe, padrÃµes e otimizaÃ§Ã£o de performance em scripts SQL.

### ğŸ“ Estrutura do Projeto

A arquitetura de arquivos foi projetada para simular um ambiente real de Data Platform, onde a lÃ³gica de execuÃ§Ã£o Ã© separada dos metadados e dos scripts.

```
/
â”œâ”€â”€ .github/
â”‚   â”œâ”€â”€ copilot-instructions.md     # Contexto global para o Copilot (Ex: Nome do Time, PadrÃµes gerais)
â”‚   â””â”€â”€ instructions/
â”‚       â”œâ”€â”€ review-validation.instructions.md # Regras para JSON e CoexistÃªncia de arquivos
â”‚       â””â”€â”€ spark-sql-review.instructions.md  # Regras para otimizaÃ§Ã£o e sintaxe SQL
â”œâ”€â”€ scripts/                      # ContÃ©m os scripts Spark SQL
â”‚   â””â”€â”€ processar_dados.sql
â”œâ”€â”€ orchestration/                # ContÃ©m os arquivos de orquestraÃ§Ã£o (JSON)
â”‚   â””â”€â”€ processar_dados.json
â””â”€â”€ metadata/                     # ContÃ©m os arquivos de metadados correspondentes (JSON)
    â””â”€â”€ processar_dados.json
```

### âš™ï¸ Como a RevisÃ£o de IA Funciona

O GitHub Copilot Code Review Ã© configurado para ser executado automaticamente em *Pull Requests* (PRs) abertas, utilizando as seguintes regras:

| Arquivo de InstruÃ§Ã£o | Escopo (`applyTo`) | Foco da RevisÃ£o |
| :--- | :--- | :--- |
| `review-validation.instructions.md` | `**/metadata/*.json`, `**/orchestration/*.json` | **Formato:** Valida sintaxe JSON. **Integridade:** Verifica se todo arquivo em `orchestration` tem um par em `metadata`. |
| `spark-sql-review.instructions.md` | `**/scripts/*.sql` | **Performance:** Sugere o uso de CTEs, eficiÃªncia de `JOIN`s. **Qualidade:** Valida a sintaxe Spark SQL e o uso de variÃ¡veis. |
| `.github/copilot-instructions.md` | Global (`**`) | Define o **TIME-DATA-PLATFORM** como proprietÃ¡rio e reforÃ§a a prioridade mÃ¡xima em *OtimizaÃ§Ã£o de Performance*. |

### ğŸ› ï¸ ConfiguraÃ§Ã£o de RevisÃ£o AutomÃ¡tica

A execuÃ§Ã£o automÃ¡tica do Copilot nas PRs Ã© garantida via **GitHub Rulesets** (Conjuntos de Regras).

O *Ruleset* estÃ¡ configurado para:

1.  **Target branches:** Aplicar a regra a *branches* de desenvolvimento (Ex: `develop`) ou de *feature* (`feature/*`).
2.  **Branch rule:** Habilitar **Automatically request Copilot code review**.
3.  **Gatilho:** Executar a revisÃ£o tanto na criaÃ§Ã£o da PR quanto em novos *pushes* de *commit* (dependendo da configuraÃ§Ã£o do *Ruleset*).

### ğŸš€ Exemplo de Uso

Ao abrir um *Pull Request* que inclua um novo job de orquestraÃ§Ã£o:

1.  O desenvolvedor envia `orchestration/novo_job.json` e `scripts/novo_job.sql`.
2.  Se o arquivo `metadata/novo_job.json` **nÃ£o** for incluÃ­do, o Copilot, acionado pelo `review-validation.instructions.md`, emitirÃ¡ um **comentÃ¡rio obrigatÃ³rio** solicitando o arquivo de metadados ausente.
3.  Se o `novo_job.sql` tiver uma subconsulta ineficiente, o Copilot, acionado pelo `spark-sql-review.instructions.md` (e o contexto global de otimizaÃ§Ã£o), sugerirÃ¡ a refatoraÃ§Ã£o para **CTEs** para atender ao padrÃ£o do time.

-----

**Desenvolvido para:** Prova de Conceito (PoC)
**Tecnologia Principal:** GitHub Copilot Code Review (Custom Instructions)
**DomÃ­nio:** Plataforma de Dados (Data Platform)